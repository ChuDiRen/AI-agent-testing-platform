"""
AI API æµ‹è¯•å…³é”®å­—æ¨¡å—
åŸºäº LLM å®ç°çš„æ™ºèƒ½ API æµ‹è¯•å…³é”®å­—

åŠŸèƒ½ç‰¹ç‚¹:
- ä½¿ç”¨ LLM é©±åŠ¨çš„æ™ºèƒ½ API æµ‹è¯•
- æ”¯æŒè‡ªç„¶è¯­è¨€æè¿°è¯·æ±‚å’Œæ–­è¨€
- æ”¯æŒå¤šç§ LLM æ¨¡å‹ (OpenAI, DeepSeek, ç¡…åŸºæµåŠ¨ç­‰)
- æ™ºèƒ½æå–å“åº”æ•°æ®
- ä¸ç°æœ‰ api-engine æ¡†æ¶æ— ç¼é›†æˆ
"""

import json
import os
import re
from typing import Optional, Dict, Any, List

import allure
import requests

# åŠ è½½ .env æ–‡ä»¶
from pathlib import Path
try:
    from dotenv import load_dotenv
    # æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶
    project_root = Path(__file__).parent.parent.parent
    env_file = project_root / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        print(f"å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_file}")
except ImportError:
    pass  # dotenv æœªå®‰è£…ï¼Œè·³è¿‡

from ..core.globalContext import g_context


class AIKeywords:
    """
    AI API æµ‹è¯•å…³é”®å­—ç±»
    
    æä¾›åŸºäº LLM çš„æ™ºèƒ½ API æµ‹è¯•èƒ½åŠ›ï¼Œ
    å¯ä»¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°æ¥æ‰§è¡Œ API æµ‹è¯•ä»»åŠ¡ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ– AI å…³é”®å­—ç±»"""
        self._config = {
            "llm_provider": "siliconflow",  # é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨
            "llm_model": "deepseek-ai/DeepSeek-V3",  # é»˜è®¤æ¨¡å‹
            "api_key": None,
            "base_url": None,
            "timeout": 30,
            "max_tokens": 4096,
        }
        self._session = requests.Session()
    
    def _get_llm_config(self, provider: str = None) -> Dict[str, Any]:
        """
        è·å– LLM é…ç½®
        
        :param provider: LLM æä¾›å•†
        :return: é…ç½®å­—å…¸ {api_key, base_url, model}
        """
        provider = provider or self._config.get("llm_provider", "siliconflow")
        
        if provider == "openai":
            return {
                "api_key": self._config.get("api_key") or os.getenv("OPENAI_API_KEY"),
                "base_url": self._config.get("base_url") or "https://api.openai.com/v1",
                "model": self._config.get("llm_model") or "gpt-4o"
            }
        
        elif provider == "deepseek":
            return {
                "api_key": self._config.get("api_key") or os.getenv("DEEPSEEK_API_KEY"),
                "base_url": self._config.get("base_url") or "https://api.deepseek.com/v1",
                "model": self._config.get("llm_model") or "deepseek-chat"
            }
        
        elif provider == "siliconflow":
            api_key = self._config.get("api_key") or os.getenv("SILICONFLOW_API_KEY")
            if not api_key:
                raise ValueError("SILICONFLOW_API_KEY æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–é€šè¿‡ api_key å‚æ•°ä¼ é€’ã€‚")
            return {
                "api_key": api_key,
                "base_url": self._config.get("base_url") or "https://api.siliconflow.cn/v1",
                "model": self._config.get("llm_model") or "deepseek-ai/DeepSeek-V3"
            }
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†: {provider}")
    
    def _call_llm(self, prompt: str, system_prompt: str = None) -> str:
        """
        è°ƒç”¨ LLM API
        
        :param prompt: ç”¨æˆ·æç¤º
        :param system_prompt: ç³»ç»Ÿæç¤º
        :return: LLM å“åº”æ–‡æœ¬
        """
        config = self._get_llm_config()
        
        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": config["model"],
            "messages": messages,
            "max_tokens": self._config.get("max_tokens", 4096),
            "temperature": 0.1  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§çš„è¾“å‡º
        }
        
        response = requests.post(
            f"{config['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=self._config.get("timeout", 30)
        )
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    # ==================== é…ç½®å…³é”®å­— ====================
    
    @allure.step("é…ç½® AI API åŠ©æ‰‹")
    def ai_configure(self, **kwargs):
        """
        é…ç½® AI API åŠ©æ‰‹å‚æ•°
        
        å‚æ•°:
            llm_provider: LLM æä¾›å•† (openai/deepseek/siliconflow)
            llm_model: æ¨¡å‹åç§° (å¯é€‰ï¼Œä½¿ç”¨é»˜è®¤)
            api_key: API å¯†é’¥ (å¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–)
            base_url: API åŸºç¡€ URL (å¯é€‰)
            timeout: è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤ 30)
        """
        if "llm_provider" in kwargs:
            self._config["llm_provider"] = kwargs["llm_provider"]
        if "llm_model" in kwargs:
            self._config["llm_model"] = kwargs["llm_model"]
        if "api_key" in kwargs:
            self._config["api_key"] = kwargs["api_key"]
        if "base_url" in kwargs:
            self._config["base_url"] = kwargs["base_url"]
        if "timeout" in kwargs:
            self._config["timeout"] = int(kwargs["timeout"])
        
        print(f"AI API åŠ©æ‰‹é…ç½®å·²æ›´æ–°: provider={self._config['llm_provider']}, model={self._config['llm_model']}")
    
    # ==================== æ ¸å¿ƒ AI å…³é”®å­— ====================
    
    @allure.step("AI ç”Ÿæˆè¯·æ±‚å‚æ•°: {task}")
    def ai_generate_request(self, **kwargs):
        """
        ä½¿ç”¨ AI æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆ API è¯·æ±‚å‚æ•°
        
        å‚æ•°:
            task: ä»»åŠ¡æè¿° (è‡ªç„¶è¯­è¨€)
            base_url: API åŸºç¡€ URL
            api_doc: API æ–‡æ¡£æè¿° (å¯é€‰)
            variable_name: ä¿å­˜ç»“æœçš„å˜é‡å (é»˜è®¤ ai_request_params)
        
        ç¤ºä¾‹:
            task: "åˆ›å»ºä¸€ä¸ªç”¨æˆ·ï¼Œç”¨æˆ·å test_userï¼Œé‚®ç®± test@example.com"
            base_url: "https://api.example.com"
        
        è¿”å›:
            ç”Ÿæˆçš„è¯·æ±‚å‚æ•°å­—å…¸ï¼ŒåŒ…å« method, url, headers, json/data ç­‰
        """
        task = kwargs.get("task")
        base_url = kwargs.get("base_url", "")
        api_doc = kwargs.get("api_doc", "")
        variable_name = kwargs.get("variable_name", "ai_request_params")
        
        if not task:
            raise ValueError("ä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©º")
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ª API æµ‹è¯•ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œç”Ÿæˆå¯¹åº”çš„ HTTP è¯·æ±‚å‚æ•°ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
    "method": "GET/POST/PUT/DELETE/PATCH",
    "url": "å®Œæ•´çš„ API URL",
    "headers": {"Content-Type": "application/json", ...},
    "json": {...} æˆ– "data": {...} æˆ– "params": {...}
}

æ³¨æ„ï¼š
1. æ ¹æ®æ“ä½œç±»å‹é€‰æ‹©åˆé€‚çš„ HTTP æ–¹æ³•
2. å¦‚æœæ˜¯ JSON æ•°æ®ï¼Œä½¿ç”¨ "json" å­—æ®µ
3. å¦‚æœæ˜¯è¡¨å•æ•°æ®ï¼Œä½¿ç”¨ "data" å­—æ®µ
4. å¦‚æœæ˜¯ URL å‚æ•°ï¼Œä½¿ç”¨ "params" å­—æ®µ
5. åªè¿”å› JSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæ–‡å­—"""

        prompt = f"""ä»»åŠ¡æè¿°: {task}
API åŸºç¡€ URL: {base_url}
"""
        if api_doc:
            prompt += f"\nAPI æ–‡æ¡£:\n{api_doc}"
        
        try:
            response = self._call_llm(prompt, system_prompt)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                request_params = json.loads(json_match.group())
            else:
                raise ValueError(f"æ— æ³•è§£æ AI å“åº”: {response}")
            
            # ä¿å­˜åˆ°å…¨å±€ä¸Šä¸‹æ–‡
            g_context().set_dict(variable_name, request_params)
            print(f"âœ“ AI ç”Ÿæˆè¯·æ±‚å‚æ•°å·²ä¿å­˜åˆ° {variable_name}")
            print(f"  è¯·æ±‚å‚æ•°: {json.dumps(request_params, ensure_ascii=False, indent=2)}")
            
            return request_params
            
        except Exception as e:
            raise RuntimeError(f"AI ç”Ÿæˆè¯·æ±‚å‚æ•°å¤±è´¥: {e}")
    
    @allure.step("AI å‘é€è¯·æ±‚: {task}")
    def ai_send_request(self, **kwargs):
        """
        ä½¿ç”¨ AI ç†è§£ä»»åŠ¡å¹¶å‘é€ API è¯·æ±‚
        
        å‚æ•°:
            task: ä»»åŠ¡æè¿° (è‡ªç„¶è¯­è¨€)
            base_url: API åŸºç¡€ URL
            api_doc: API æ–‡æ¡£æè¿° (å¯é€‰)
            headers: é¢å¤–çš„è¯·æ±‚å¤´ (å¯é€‰)
        
        ç¤ºä¾‹:
            task: "è·å–ç”¨æˆ·åˆ—è¡¨"
            base_url: "https://api.example.com"
        """
        task = kwargs.get("task")
        base_url = kwargs.get("base_url", "")
        extra_headers = kwargs.get("headers", {})
        
        # å…ˆç”Ÿæˆè¯·æ±‚å‚æ•°
        request_params = self.ai_generate_request(**kwargs)
        
        # åˆå¹¶é¢å¤–çš„è¯·æ±‚å¤´
        if extra_headers:
            request_params["headers"] = {**request_params.get("headers", {}), **extra_headers}
        
        # å‘é€è¯·æ±‚
        method = request_params.pop("method", "GET")
        url = request_params.pop("url", base_url)
        
        print(f"ğŸš€ å‘é€ {method} è¯·æ±‚åˆ° {url}")
        
        response = self._session.request(method=method, url=url, **request_params)
        
        # ä¿å­˜å“åº”åˆ°å…¨å±€ä¸Šä¸‹æ–‡
        g_context().set_dict("current_response", response)
        
        response_data = {
            "url": response.url,
            "method": method,
            "status_code": response.status_code,
            "headers": dict(response.headers),
            "response": response.text
        }
        g_context().set_dict("current_response_data", response_data)
        
        print(f"âœ“ å“åº”çŠ¶æ€ç : {response.status_code}")
        
        return response
    
    @allure.step("AI æ–­è¨€å“åº”: {assertion}")
    def ai_assert_response(self, **kwargs):
        """
        ä½¿ç”¨ AI æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°éªŒè¯ API å“åº”
        
        å‚æ•°:
            assertion: æ–­è¨€æè¿° (è‡ªç„¶è¯­è¨€)
            response: å“åº”å¯¹è±¡ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ current_response)
        
        ç¤ºä¾‹:
            assertion: "çŠ¶æ€ç åº”è¯¥æ˜¯ 200"
            assertion: "å“åº”ä¸­åº”è¯¥åŒ…å« user_id å­—æ®µ"
            assertion: "è¿”å›çš„ç”¨æˆ·åˆ—è¡¨åº”è¯¥ä¸ä¸ºç©º"
        """
        assertion = kwargs.get("assertion")
        response = kwargs.get("response") or g_context().get_dict("current_response")
        
        if not assertion:
            raise ValueError("æ–­è¨€æè¿°ä¸èƒ½ä¸ºç©º")
        
        if response is None:
            raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„å“åº”ï¼Œè¯·å…ˆå‘é€è¯·æ±‚")
        
        # å‡†å¤‡å“åº”ä¿¡æ¯
        try:
            response_json = response.json()
            response_body = json.dumps(response_json, ensure_ascii=False, indent=2)
        except:
            response_body = response.text
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ª API æµ‹è¯•æ–­è¨€ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„æ–­è¨€æè¿°ï¼ŒéªŒè¯ API å“åº”æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
    "passed": true/false,
    "reason": "æ–­è¨€é€šè¿‡/å¤±è´¥çš„åŸå› "
}"""

        prompt = f"""æ–­è¨€æè¿°: {assertion}

å“åº”ä¿¡æ¯:
- çŠ¶æ€ç : {response.status_code}
- å“åº”å¤´: {dict(response.headers)}
- å“åº”ä½“:
{response_body}

è¯·éªŒè¯å“åº”æ˜¯å¦ç¬¦åˆæ–­è¨€æè¿°ã€‚"""

        try:
            result = self._call_llm(prompt, system_prompt)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                assertion_result = json.loads(json_match.group())
            else:
                raise ValueError(f"æ— æ³•è§£æ AI å“åº”: {result}")
            
            passed = assertion_result.get("passed", False)
            reason = assertion_result.get("reason", "")
            
            if passed:
                print(f"âœ“ æ–­è¨€é€šè¿‡: {reason}")
            else:
                print(f"âœ— æ–­è¨€å¤±è´¥: {reason}")
                raise AssertionError(f"AI æ–­è¨€å¤±è´¥: {assertion}\nåŸå› : {reason}")
            
            return assertion_result
            
        except AssertionError:
            raise
        except Exception as e:
            raise RuntimeError(f"AI æ–­è¨€æ‰§è¡Œå¤±è´¥: {e}")
    
    @allure.step("AI æå–æ•°æ®: {extraction}")
    def ai_extract_data(self, **kwargs):
        """
        ä½¿ç”¨ AI ä»å“åº”ä¸­æ™ºèƒ½æå–æ•°æ®
        
        å‚æ•°:
            extraction: æå–æè¿° (è‡ªç„¶è¯­è¨€)
            response: å“åº”å¯¹è±¡ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ current_response)
            variable_name: ä¿å­˜ç»“æœçš„å˜é‡å (é»˜è®¤ ai_extracted_data)
        
        ç¤ºä¾‹:
            extraction: "æå–ç¬¬ä¸€ä¸ªç”¨æˆ·çš„ ID"
            extraction: "æå–æ‰€æœ‰ç”¨æˆ·çš„é‚®ç®±åœ°å€"
            extraction: "æå– token å­—æ®µçš„å€¼"
        """
        extraction = kwargs.get("extraction")
        response = kwargs.get("response") or g_context().get_dict("current_response")
        variable_name = kwargs.get("variable_name", "ai_extracted_data")
        
        if not extraction:
            raise ValueError("æå–æè¿°ä¸èƒ½ä¸ºç©º")
        
        if response is None:
            raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„å“åº”ï¼Œè¯·å…ˆå‘é€è¯·æ±‚")
        
        # å‡†å¤‡å“åº”ä¿¡æ¯
        try:
            response_json = response.json()
            response_body = json.dumps(response_json, ensure_ascii=False, indent=2)
        except:
            response_body = response.text
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„æè¿°ï¼Œä» API å“åº”ä¸­æå–æŒ‡å®šçš„æ•°æ®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
    "extracted_data": æå–çš„æ•°æ®ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€æ•°å­—ã€æ•°ç»„æˆ–å¯¹è±¡ï¼‰,
    "jsonpath": "å¯¹åº”çš„ JSONPath è¡¨è¾¾å¼ï¼ˆå¦‚æœé€‚ç”¨ï¼‰"
}"""

        prompt = f"""æå–æè¿°: {extraction}

å“åº”ä½“:
{response_body}

è¯·æå–æŒ‡å®šçš„æ•°æ®ã€‚"""

        try:
            result = self._call_llm(prompt, system_prompt)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                extraction_result = json.loads(json_match.group())
            else:
                raise ValueError(f"æ— æ³•è§£æ AI å“åº”: {result}")
            
            extracted_data = extraction_result.get("extracted_data")
            jsonpath_expr = extraction_result.get("jsonpath", "")
            
            # ä¿å­˜åˆ°å…¨å±€ä¸Šä¸‹æ–‡
            g_context().set_dict(variable_name, extracted_data)
            
            print(f"âœ“ å·²æå–æ•°æ®å¹¶ä¿å­˜åˆ° {variable_name}")
            print(f"  æå–çš„æ•°æ®: {extracted_data}")
            if jsonpath_expr:
                print(f"  JSONPath: {jsonpath_expr}")
            
            return extracted_data
            
        except Exception as e:
            raise RuntimeError(f"AI æ•°æ®æå–å¤±è´¥: {e}")
    
    @allure.step("AI ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    def ai_generate_test_cases(self, **kwargs):
        """
        ä½¿ç”¨ AI æ ¹æ® API æ–‡æ¡£ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        
        å‚æ•°:
            api_doc: API æ–‡æ¡£æè¿°
            test_scenarios: æµ‹è¯•åœºæ™¯æè¿° (å¯é€‰)
            variable_name: ä¿å­˜ç»“æœçš„å˜é‡å (é»˜è®¤ ai_test_cases)
        
        ç¤ºä¾‹:
            api_doc: "POST /users - åˆ›å»ºç”¨æˆ·ï¼Œå‚æ•°: name(å¿…å¡«), email(å¿…å¡«), age(å¯é€‰)"
            test_scenarios: "æ­£å¸¸åˆ›å»ºã€ç¼ºå°‘å¿…å¡«å‚æ•°ã€å‚æ•°æ ¼å¼é”™è¯¯"
        """
        api_doc = kwargs.get("api_doc")
        test_scenarios = kwargs.get("test_scenarios", "æ­£å¸¸åœºæ™¯ã€è¾¹ç•Œåœºæ™¯ã€å¼‚å¸¸åœºæ™¯")
        variable_name = kwargs.get("variable_name", "ai_test_cases")
        
        if not api_doc:
            raise ValueError("API æ–‡æ¡£æè¿°ä¸èƒ½ä¸ºç©º")
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ª API æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ã€‚æ ¹æ® API æ–‡æ¡£ç”Ÿæˆå…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
    "test_cases": [
        {
            "name": "æµ‹è¯•ç”¨ä¾‹åç§°",
            "description": "æµ‹è¯•ç”¨ä¾‹æè¿°",
            "request": {
                "method": "HTTPæ–¹æ³•",
                "url": "APIè·¯å¾„",
                "headers": {},
                "json": {} æˆ– "data": {} æˆ– "params": {}
            },
            "expected": {
                "status_code": æœŸæœ›çŠ¶æ€ç ,
                "assertions": ["æ–­è¨€1", "æ–­è¨€2"]
            }
        }
    ]
}"""

        prompt = f"""API æ–‡æ¡£:
{api_doc}

æµ‹è¯•åœºæ™¯è¦æ±‚: {test_scenarios}

è¯·ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹ã€‚"""

        try:
            result = self._call_llm(prompt, system_prompt)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                test_cases_result = json.loads(json_match.group())
            else:
                raise ValueError(f"æ— æ³•è§£æ AI å“åº”: {result}")
            
            test_cases = test_cases_result.get("test_cases", [])
            
            # ä¿å­˜åˆ°å…¨å±€ä¸Šä¸‹æ–‡
            g_context().set_dict(variable_name, test_cases)
            
            print(f"âœ“ å·²ç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶ä¿å­˜åˆ° {variable_name}")
            for i, tc in enumerate(test_cases, 1):
                print(f"  {i}. {tc.get('name', 'æœªå‘½å')}")
            
            return test_cases
            
        except Exception as e:
            raise RuntimeError(f"AI ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
    
    @allure.step("AI åˆ†æå“åº”")
    def ai_analyze_response(self, **kwargs):
        """
        ä½¿ç”¨ AI åˆ†æ API å“åº”ï¼Œæä¾›æµ‹è¯•å»ºè®®
        
        å‚æ•°:
            response: å“åº”å¯¹è±¡ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ current_response)
            focus: åˆ†æé‡ç‚¹ (å¯é€‰ï¼Œå¦‚ "æ€§èƒ½"ã€"å®‰å…¨"ã€"æ•°æ®å®Œæ•´æ€§")
        
        è¿”å›:
            åˆ†æç»“æœå’Œå»ºè®®
        """
        response = kwargs.get("response") or g_context().get_dict("current_response")
        focus = kwargs.get("focus", "")
        
        if response is None:
            raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„å“åº”ï¼Œè¯·å…ˆå‘é€è¯·æ±‚")
        
        # å‡†å¤‡å“åº”ä¿¡æ¯
        try:
            response_json = response.json()
            response_body = json.dumps(response_json, ensure_ascii=False, indent=2)
        except:
            response_body = response.text
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ª API æµ‹è¯•åˆ†æä¸“å®¶ã€‚åˆ†æ API å“åº”å¹¶æä¾›æµ‹è¯•å»ºè®®ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼š
{
    "summary": "å“åº”æ‘˜è¦",
    "data_structure": "æ•°æ®ç»“æ„åˆ†æ",
    "potential_issues": ["æ½œåœ¨é—®é¢˜1", "æ½œåœ¨é—®é¢˜2"],
    "test_suggestions": ["æµ‹è¯•å»ºè®®1", "æµ‹è¯•å»ºè®®2"]
}"""

        prompt = f"""è¯·åˆ†æä»¥ä¸‹ API å“åº”:

çŠ¶æ€ç : {response.status_code}
å“åº”æ—¶é—´: {response.elapsed.total_seconds()}ç§’
å“åº”å¤´: {dict(response.headers)}
å“åº”ä½“:
{response_body}
"""
        if focus:
            prompt += f"\nåˆ†æé‡ç‚¹: {focus}"

        try:
            result = self._call_llm(prompt, system_prompt)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                analysis = json.loads(json_match.group())
            else:
                analysis = {"summary": result}
            
            print(f"ğŸ“Š å“åº”åˆ†æ:")
            print(f"  æ‘˜è¦: {analysis.get('summary', 'N/A')}")
            if analysis.get('potential_issues'):
                print(f"  æ½œåœ¨é—®é¢˜: {', '.join(analysis['potential_issues'])}")
            if analysis.get('test_suggestions'):
                print(f"  æµ‹è¯•å»ºè®®: {', '.join(analysis['test_suggestions'])}")
            
            return analysis
            
        except Exception as e:
            raise RuntimeError(f"AI åˆ†æå“åº”å¤±è´¥: {e}")


# åˆ›å»ºå…¨å±€å®ä¾‹ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨
_ai_keywords = None


def get_ai_keywords() -> AIKeywords:
    """è·å– AIKeywords å•ä¾‹å®ä¾‹"""
    global _ai_keywords
    if _ai_keywords is None:
        _ai_keywords = AIKeywords()
    return _ai_keywords
