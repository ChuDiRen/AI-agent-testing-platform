"""
AnythingChatRAG - å¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢å¼•æ“

æ”¯æŒ6ç§æ£€ç´¢æ¨¡å¼ï¼š
1. local - æœ¬åœ°å®ä½“å’Œå…³ç³»æ£€ç´¢
2. global - å…¨å±€çŸ¥è¯†å›¾è°±æ¢ç´¢
3. hybrid - æ··åˆæ£€ç´¢ç­–ç•¥
4. naive - å‘é‡ç›¸ä¼¼æ€§æœç´¢
5. mix - ç»¼åˆæ£€ç´¢ï¼ˆæ¨èï¼‰
6. bypass - ç›´æ¥æŸ¥è¯¢
"""
import asyncio
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
import json
from datetime import datetime
import hashlib
import re

from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
# from langchain.vectorstores import Chroma
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain.document_loaders import (
#     PyPDFLoader, 
#     Docx2txtLoader, 
#     UnstructuredExcelLoader,
#     UnstructuredMarkdownLoader
# )
# from langchain.schema import Document


class RAGQuery(BaseModel):
    """RAGæŸ¥è¯¢å‚æ•°"""
    query: str = Field(description="æŸ¥è¯¢æ–‡æœ¬")
    mode: str = Field(default="mix", description="æ£€ç´¢æ¨¡å¼")
    top_k: int = Field(default=10, description="è¿”å›ç»“æœæ•°é‡")
    chunk_top_k: int = Field(default=5, description="æ–‡æœ¬å—æ•°é‡")
    enable_rerank: bool = Field(default=True, description="å¯ç”¨é‡æ’åº")


class RAGResult(BaseModel):
    """RAGæ£€ç´¢ç»“æœ"""
    entities: List[Dict[str, Any]] = Field(default_factory=list, description="å®ä½“ä¿¡æ¯")
    relationships: List[Dict[str, Any]] = Field(default_factory=list, description="å…³ç³»ä¿¡æ¯")
    text_chunks: List[Dict[str, Any]] = Field(default_factory=list, description="æ–‡æœ¬å—")
    references: List[Dict[str, Any]] = Field(default_factory=list, description="å¼•ç”¨ä¿¡æ¯")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="å…ƒæ•°æ®")


class AnythingChatRAG:
    """AnythingChatRAGå¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢å¼•æ“"""
    
    def __init__(self, workspace_dir: Optional[Path] = None):
        self.workspace_dir = workspace_dir or Path("./rag_workspace")
        self.workspace_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self.vectorstore = None
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002",
            base_url="https://api.siliconflow.cn/v1",
            api_key="YOUR_SILICONFLOW_API_KEY"
        )
        
        # åˆå§‹åŒ–LLM - ä½¿ç”¨ç¡…åŸºæµåŠ¨
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            temperature=0.3,
            base_url="https://api.siliconflow.cn/v1",
            api_key="YOUR_SILICONFLOW_API_KEY"
        )
        
        # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
        self.document_processors = {
            'pdf': lambda x: [],  # PyPDFLoader,
            'docx': lambda x: [],  # Docx2txtLoader,
            'xlsx': lambda x: [],  # UnstructuredExcelLoader,
            'md': lambda x: [],  # UnstructuredMarkdownLoader,
            'txt': lambda x: []  # lambda x: [Document(page_content=x, metadata={})]
        }
        
        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±
        self.knowledge_graph = {}
        self.entity_index = {}
        self.relationship_index = {}
        
        # åˆå§‹åŒ–æ£€ç´¢æ¨¡å¼
        self.retrieval_modes = {
            'local': self._local_retrieval,
            'global': self._global_retrieval,
            'hybrid': self._hybrid_retrieval,
            'naive': self._naive_retrieval,
            'mix': self._mix_retrieval,
            'bypass': self._bypass_retrieval
        }
    
    async def aquery(self, query: str, mode: str = "mix", **kwargs) -> RAGResult:
        """å¼‚æ­¥RAGæŸ¥è¯¢"""
        rag_query = RAGQuery(
            query=query,
            mode=mode,
            top_k=kwargs.get('top_k', 10),
            chunk_top_k=kwargs.get('chunk_top_k', 5),
            enable_rerank=kwargs.get('enable_rerank', True)
        )
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ£€ç´¢æ–¹æ³•
        if mode in self.retrieval_modes:
            result = await self.retrieval_modes[mode](rag_query)
        else:
            result = await self._mix_retrieval(rag_query)
        
        return result
    
    async def _local_retrieval(self, query: RAGQuery) -> RAGResult:
        """æœ¬åœ°å®ä½“å’Œå…³ç³»æ£€ç´¢"""
        print(f"ğŸ” Local retrieval: {query.query}")
        
        # å®ä½“æå–
        entities = await self._extract_entities(query.query)
        
        # å…³ç³»æ£€ç´¢
        relationships = await self._extract_relationships(query.query, entities)
        
        # æœ¬åœ°æ–‡æ¡£æ£€ç´¢
        local_chunks = await self._search_local_documents(query.query, query.top_k)
        
        return RAGResult(
            entities=entities,
            relationships=relationships,
            text_chunks=local_chunks,
            references=[],
            metadata={"mode": "local", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _global_retrieval(self, query: RAGQuery) -> RAGResult:
        """å…¨å±€çŸ¥è¯†å›¾è°±æ¢ç´¢"""
        print(f"ğŸŒ Global retrieval: {query.query}")
        
        # å…¨å±€çŸ¥è¯†å›¾è°±æŸ¥è¯¢
        global_entities = await self._query_knowledge_graph(query.query)
        
        # å…¨å±€å…³ç³»æ¢ç´¢
        global_relationships = await self._explore_global_relationships(query.query)
        
        # å…¨å±€æ–‡æ¡£æ£€ç´¢
        global_chunks = await self._search_global_documents(query.query, query.top_k)
        
        return RAGResult(
            entities=global_entities,
            relationships=global_relationships,
            text_chunks=global_chunks,
            references=[],
            metadata={"mode": "global", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _hybrid_retrieval(self, query: RAGQuery) -> RAGResult:
        """æ··åˆæ£€ç´¢ç­–ç•¥"""
        print(f"ğŸ”„ Hybrid retrieval: {query.query}")
        
        # å¹¶è¡Œæ‰§è¡Œæœ¬åœ°å’Œå…¨å±€æ£€ç´¢
        local_task = self._local_retrieval(query)
        global_task = self._global_retrieval(query)
        
        local_result, global_result = await asyncio.gather(local_task, global_task)
        
        # åˆå¹¶ç»“æœ
        merged_entities = local_result.entities + global_result.entities
        merged_relationships = local_result.relationships + global_result.relationships
        merged_chunks = local_result.text_chunks + global_result.text_chunks
        
        return RAGResult(
            entities=merged_entities,
            relationships=merged_relationships,
            text_chunks=merged_chunks,
            references=[],
            metadata={"mode": "hybrid", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _naive_retrieval(self, query: RAGQuery) -> RAGResult:
        """å‘é‡ç›¸ä¼¼æ€§æœç´¢"""
        print(f"ğŸ§  Naive retrieval: {query.query}")
        
        if not self.vectorstore:
            await self._initialize_vectorstore()
        
        # å‘é‡ç›¸ä¼¼æ€§æœç´¢
        similar_docs = await self.vectorstore.asimilarity_search(
            query.query, 
            k=query.top_k
        )
        
        text_chunks = [
            {
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity": 1.0 - getattr(doc, 'score', 0.0)
            }
            for doc in similar_docs
        ]
        
        return RAGResult(
            entities=[],
            relationships=[],
            text_chunks=text_chunks,
            references=[],
            metadata={"mode": "naive", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _mix_retrieval(self, query: RAGQuery) -> RAGResult:
        """ç»¼åˆæ£€ç´¢ï¼ˆæ¨èï¼‰"""
        print(f"ğŸ¯ Mix retrieval: {query.query}")
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ£€ç´¢æ¨¡å¼
        tasks = [
            self._local_retrieval(query),
            self._global_retrieval(query),
            self._naive_retrieval(query)
        ]
        
        local_result, global_result, naive_result = await asyncio.gather(*tasks)
        
        # æ™ºèƒ½åˆå¹¶å’Œé‡æ’åº
        mixed_entities = await self._merge_and_rerank_entities([
            local_result.entities,
            global_result.entities
        ])
        
        mixed_relationships = await self._merge_and_rerank_relationships([
            local_result.relationships,
            global_result.relationships
        ])
        
        mixed_chunks = await self._merge_and_rerank_chunks([
            local_result.text_chunks,
            global_result.text_chunks,
            naive_result.text_chunks
        ])
        
        return RAGResult(
            entities=mixed_entities,
            relationships=mixed_relationships,
            text_chunks=mixed_chunks,
            references=[],
            metadata={"mode": "mix", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _bypass_retrieval(self, query: RAGQuery) -> RAGResult:
        """ç›´æ¥æŸ¥è¯¢"""
        print(f"âš¡ Bypass retrieval: {query.query}")
        
        # ç›´æ¥LLMæŸ¥è¯¢
        direct_response = await self.llm.ainvoke(query.query)
        
        text_chunks = [
            {
                "content": direct_response.content,
                "metadata": {"source": "direct_llm"},
                "similarity": 1.0
            }
        ]
        
        return RAGResult(
            entities=[],
            relationships=[],
            text_chunks=text_chunks,
            references=[],
            metadata={"mode": "bypass", "timestamp": datetime.utcnow().isoformat()}
        )
    
    async def _extract_entities(self, query: str) -> List[Dict[str, Any]]:
        """æå–å®ä½“"""
        # ä½¿ç”¨LLMæå–APIç›¸å…³çš„å®ä½“
        prompt = f"""
        ä»ä»¥ä¸‹æŸ¥è¯¢ä¸­æå–APIç›¸å…³çš„å®ä½“ä¿¡æ¯ï¼š
        æŸ¥è¯¢ï¼š{query}
        
        è¯·æå–ä»¥ä¸‹ç±»å‹çš„å®ä½“ï¼š
        1. APIæ¥å£åç§°
        2. HTTPæ–¹æ³•ï¼ˆGET, POST, PUT, DELETEç­‰ï¼‰
        3. å‚æ•°åç§°
        4. è®¤è¯æ–¹å¼
        5. å“åº”å­—æ®µ
        
        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "entities": [
                {{
                    "type": "api_endpoint",
                    "name": "æ¥å£åç§°",
                    "description": "æè¿°",
                    "confidence": 0.9
                }}
            ]
        }}
        """
        
        response = await self.llm.ainvoke(prompt)
        
        try:
            # è§£æJSONå“åº”
            import json
            data = json.loads(response.content)
            return data.get("entities", [])
        except:
            return []
    
    async def _extract_relationships(self, query: str, entities: List[Dict]) -> List[Dict[str, Any]]:
        """æå–å…³ç³»"""
        # åŸºäºå®ä½“æå–å…³ç³»
        relationships = []
        
        for entity in entities:
            if entity.get("type") == "api_endpoint":
                # APIä¾èµ–å…³ç³»
                relationships.append({
                    "source": entity.get("name"),
                    "target": "authentication",
                    "relationship_type": "requires",
                    "confidence": 0.8
                })
        
        return relationships
    
    async def _search_local_documents(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æœç´¢æœ¬åœ°æ–‡æ¡£"""
        # æ¨¡æ‹Ÿæœ¬åœ°æ–‡æ¡£æœç´¢
        local_docs = [
            {
                "content": f"APIæ¥å£æ–‡æ¡£ï¼š{query}çš„è¯¦ç»†è¯´æ˜",
                "metadata": {"source": "local_api_docs", "type": "api_spec"},
                "similarity": 0.9
            },
            {
                "content": f"æµ‹è¯•ç”¨ä¾‹ï¼š{query}ç›¸å…³çš„æµ‹è¯•åœºæ™¯",
                "metadata": {"source": "local_test_cases", "type": "test_case"},
                "similarity": 0.8
            }
        ]
        
        return local_docs[:top_k]
    
    async def _query_knowledge_graph(self, query: str) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢çŸ¥è¯†å›¾è°±"""
        # æ¨¡æ‹ŸçŸ¥è¯†å›¾è°±æŸ¥è¯¢
        kg_entities = [
            {
                "type": "api_module",
                "name": "user_management",
                "description": "ç”¨æˆ·ç®¡ç†æ¨¡å—",
                "confidence": 0.95
            },
            {
                "type": "api_endpoint",
                "name": "/api/users",
                "description": "ç”¨æˆ·åˆ—è¡¨æ¥å£",
                "confidence": 0.9
            }
        ]
        
        return kg_entities
    
    async def _explore_global_relationships(self, query: str) -> List[Dict[str, Any]]:
        """æ¢ç´¢å…¨å±€å…³ç³»"""
        global_relationships = [
            {
                "source": "user_management",
                "target": "authentication",
                "relationship_type": "depends_on",
                "confidence": 0.85
            },
            {
                "source": "/api/users",
                "target": "jwt_token",
                "relationship_type": "requires",
                "confidence": 0.9
            }
        ]
        
        return global_relationships
    
    async def _search_global_documents(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æœç´¢å…¨å±€æ–‡æ¡£"""
        global_docs = [
            {
                "content": f"å…¨å±€APIè§„èŒƒï¼š{query}çš„å®Œæ•´æ–‡æ¡£",
                "metadata": {"source": "global_api_specs", "type": "api_doc"},
                "similarity": 0.92
            }
        ]
        
        return global_docs[:top_k]
    
    async def _initialize_vectorstore(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = Chroma(
            collection_name="api_knowledge",
            embedding_function=self.embeddings,
            persist_directory=str(self.workspace_dir / "vectorstore")
        )
    
    async def _merge_and_rerank_entities(self, entity_lists: List[List[Dict]]) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œé‡æ’åºå®ä½“"""
        merged = []
        seen_entities = set()
        
        for entity_list in entity_lists:
            for entity in entity_list:
                entity_key = f"{entity.get('type', '')}:{entity.get('name', '')}"
                if entity_key not in seen_entities:
                    merged.append(entity)
                    seen_entities.add(entity_key)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        merged.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        return merged[:10]
    
    async def _merge_and_rerank_relationships(self, relationship_lists: List[List[Dict]]) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œé‡æ’åºå…³ç³»"""
        merged = []
        seen_relationships = set()
        
        for relationship_list in relationship_lists:
            for rel in relationship_list:
                rel_key = f"{rel.get('source', '')}:{rel.get('target', '')}:{rel.get('relationship_type', '')}"
                if rel_key not in seen_relationships:
                    merged.append(rel)
                    seen_relationships.add(rel_key)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        merged.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        return merged[:10]
    
    async def _merge_and_rerank_chunks(self, chunk_lists: List[List[Dict]]) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œé‡æ’åºæ–‡æœ¬å—"""
        merged = []
        seen_chunks = set()
        
        for chunk_list in chunk_lists:
            for chunk in chunk_list:
                chunk_key = hashlib.md5(chunk.get('content', '').encode()).hexdigest()
                if chunk_key not in seen_chunks:
                    merged.append(chunk)
                    seen_chunks.add(chunk_key)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        merged.sort(key=lambda x: x.get('similarity', 0), reverse=True)
        return merged[:10]
