"""æ•°æ®å¤„ç†ä¸“å®¶ (Tool Agent) - éLLMçš„ç¡®å®šæ€§ä»»åŠ¡å¤„ç†

èŒè´£:
- æ”¶é›†å’Œæ•´ç†æ•°æ® (å»é‡ã€éªŒè¯)
- å¯¼å‡ºä¸ºXMindæ€ç»´å¯¼å›¾
- å¯¼å‡ºä¸ºExcelè¡¨æ ¼
- ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š

è®¾è®¡ç†å¿µ:
- è¿™ä¸æ˜¯ä¸€ä¸ªåŸºäºLLMçš„Agentï¼Œè€Œæ˜¯ä¸€ä¸ªè‡ªå®šä¹‰èŠ‚ç‚¹å‡½æ•°
- æ•°æ®å¤„ç†æ˜¯ç¡®å®šæ€§ä»»åŠ¡ï¼Œä¸éœ€è¦"ç†è§£"å’Œ"åˆ›é€ "
- å›ºå®šçš„æ‰§è¡Œæµç¨‹æ›´å¿«ã€æ›´å‡†ç¡®ã€æ›´å¯æ§
- é™ä½æˆæœ¬ï¼ˆæ•°æ®å¤„ç†ä¸æ¶ˆè€—LLM Tokenï¼‰
"""
import asyncio
import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from difflib import SequenceMatcher

from ..models import TestCaseState, TestCaseSuite, TestCaseModule, TestCaseItem


class MarkdownTestCaseParser:
    """Markdown æµ‹è¯•ç”¨ä¾‹è§£æå™¨ - ä»Markdownæ ¼å¼æ–‡æœ¬ä¸­æå–æµ‹è¯•ç”¨ä¾‹"""
    
    @staticmethod
    def parse(text: str) -> Tuple[Optional[TestCaseSuite], List[str]]:
        """è§£æMarkdownæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹
        
        æ”¯æŒæ ¼å¼:
        ### TC-001 ç”¨ä¾‹æ ‡é¢˜
        **ä¼˜å…ˆçº§**ï¼šP0
        **å‰ç½®æ¡ä»¶**ï¼š...
        **æµ‹è¯•æ­¥éª¤**ï¼š...
        **é¢„æœŸç»“æœ**ï¼š...
        **æµ‹è¯•æ•°æ®**ï¼š...
        """
        errors = []
        cases_list = []
        
        # ä½¿ç”¨findallæ‰¾åˆ°æ‰€æœ‰ç”¨ä¾‹æ ‡é¢˜ä½ç½®
        # æ”¯æŒ ## TC-001, ### TC-001, #### TC-001 æ ¼å¼
        case_header_pattern = r'#{2,4}\s*(TC-?\d+)\s*([^\n]*)'
        headers = list(re.finditer(case_header_pattern, text))
        
        if not headers:
            return None, ["æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹ (æ ¼å¼: ### TC-001 ç”¨ä¾‹æ ‡é¢˜)"]
        
        # è§£ææ¯ä¸ªç”¨ä¾‹
        for idx, match in enumerate(headers):
            case_id = match.group(1)
            case_title = match.group(2).strip() or case_id
            
            # è·å–ç”¨ä¾‹å†…å®¹ (ä»å½“å‰æ ‡é¢˜åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ä¹‹é—´)
            start = match.end()
            end = headers[idx + 1].start() if idx + 1 < len(headers) else len(text)
            content = text[start:end]
            
            # æå–å„å­—æ®µ
            priority = MarkdownTestCaseParser._extract_field(content, r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*(\S+)')
            precondition = MarkdownTestCaseParser._extract_field(content, r'\*\*å‰ç½®æ¡ä»¶\*\*[ï¼š:]([^*]+?)(?=\*\*|$)')
            steps = MarkdownTestCaseParser._extract_list(content, r'\*\*æµ‹è¯•æ­¥éª¤\*\*[ï¼š:]([^*]+?)(?=\*\*|$)')
            expected = MarkdownTestCaseParser._extract_list(content, r'\*\*é¢„æœŸç»“æœ\*\*[ï¼š:]([^*]+?)(?=\*\*|$)')
            test_data = MarkdownTestCaseParser._extract_field(content, r'\*\*æµ‹è¯•æ•°æ®\*\*[ï¼š:]([^*]+?)(?=\*\*|---|$)')
            
            # åˆ›å»ºç”¨ä¾‹
            case = TestCaseItem(
                ç”¨ä¾‹ç¼–å·=case_id,
                ç”¨ä¾‹æ ‡é¢˜=case_title,
                ä¼˜å…ˆçº§=priority or "P1",
                å‰ç½®æ¡ä»¶=precondition.strip() if precondition else "",
                æµ‹è¯•æ­¥éª¤=steps,
                é¢„æœŸç»“æœ=expected,
                æµ‹è¯•æ•°æ®={"raw": test_data.strip()} if test_data else {}
            )
            cases_list.append(case)
        
        if not cases_list:
            return None, ["è§£æå¤±è´¥: æœªæå–åˆ°ä»»ä½•æµ‹è¯•ç”¨ä¾‹"]
        
        # æ„å»ºTestCaseSuite
        suite = TestCaseSuite(æµ‹è¯•ç”¨ä¾‹=[
            TestCaseModule(åŠŸèƒ½æ¨¡å—="æµ‹è¯•ç”¨ä¾‹", æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨=cases_list)
        ])
        
        return suite, errors
    
    @staticmethod
    def _extract_field(text: str, pattern: str) -> Optional[str]:
        """æå–å•ä¸ªå­—æ®µ"""
        match = re.search(pattern, text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return None
    
    @staticmethod
    def _extract_list(text: str, pattern: str) -> List[str]:
        """æå–åˆ—è¡¨å­—æ®µ"""
        match = re.search(pattern, text, re.DOTALL)
        if not match:
            return []
        
        content = match.group(1)
        # æŒ‰æ•°å­—ç¼–å·åˆ†å‰²
        items = re.findall(r'\d+\.\s*([^\n]+)', content)
        return [item.strip() for item in items if item.strip()]


class PydanticJSONParser:
    """Pydantic JSON è§£æå™¨ - ä»æ–‡æœ¬ä¸­æå–å¹¶éªŒè¯æµ‹è¯•ç”¨ä¾‹"""
    
    @staticmethod
    def extract_json_from_text(text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹
        
        æ”¯æŒå¤šç§æ ¼å¼:
        - çº¯JSON
        - Markdownä»£ç å—ä¸­çš„JSON
        - æ··åˆæ–‡æœ¬ä¸­çš„JSON
        """
        # å°è¯•ç›´æ¥è§£æ
        text = text.strip()
        if text.startswith('{') or text.startswith('['):
            return text
        
        # å°è¯•ä»Markdownä»£ç å—ä¸­æå–
        json_patterns = [
            r'```json\s*([\s\S]*?)\s*```',  # ```json ... ```
            r'```\s*([\s\S]*?)\s*```',       # ``` ... ```
            r'\{[\s\S]*"æµ‹è¯•ç”¨ä¾‹"[\s\S]*\}',  # ç›´æ¥åŒ¹é…JSONå¯¹è±¡
        ]
        
        for pattern in json_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                    json.loads(match if isinstance(match, str) else match)
                    return match if isinstance(match, str) else match
                except json.JSONDecodeError:
                    continue
        
        return None
    
    @staticmethod
    def parse_test_cases(json_text: str) -> Tuple[Optional[TestCaseSuite], List[str]]:
        """è§£ææµ‹è¯•ç”¨ä¾‹JSONå¹¶éªŒè¯
        
        Returns:
            (TestCaseSuite, errors): è§£æç»“æœå’Œé”™è¯¯åˆ—è¡¨
        """
        errors = []
        
        try:
            data = json.loads(json_text)
        except json.JSONDecodeError as e:
            errors.append(f"JSONè§£æé”™è¯¯: {str(e)}")
            return None, errors
        
        # å°è¯•è§£æä¸ºTestCaseSuite
        try:
            if isinstance(data, dict) and "æµ‹è¯•ç”¨ä¾‹" in data:
                suite = TestCaseSuite(**data)
                return suite, errors
            elif isinstance(data, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼ŒåŒ…è£…ä¸ºå¥—ä»¶
                suite = TestCaseSuite(æµ‹è¯•ç”¨ä¾‹=[
                    TestCaseModule(**item) if isinstance(item, dict) else item
                    for item in data
                ])
                return suite, errors
        except Exception as e:
            errors.append(f"æ•°æ®éªŒè¯é”™è¯¯: {str(e)}")
        
        return None, errors
    
    @staticmethod
    def parse_from_text(text: str) -> Tuple[Optional[TestCaseSuite], List[str]]:
        """ä»æ–‡æœ¬ä¸­è§£ææµ‹è¯•ç”¨ä¾‹ (æ”¯æŒJSONå’ŒMarkdownæ ¼å¼)"""
        # 1. å…ˆå°è¯•JSONè§£æ
        json_text = PydanticJSONParser.extract_json_from_text(text)
        if json_text:
            suite, errors = PydanticJSONParser.parse_test_cases(json_text)
            if suite and suite.total_cases > 0:
                return suite, errors
        
        # 2. å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•Markdownè§£æ
        suite, errors = MarkdownTestCaseParser.parse(text)
        if suite and suite.total_cases > 0:
            return suite, errors
        
        return None, ["æœªæ‰¾åˆ°æœ‰æ•ˆçš„æµ‹è¯•ç”¨ä¾‹å†…å®¹ (æ”¯æŒJSONæˆ–Markdownæ ¼å¼)"]


class TestCaseDeduplicator:
    """æµ‹è¯•ç”¨ä¾‹å»é‡å™¨ - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦"""
    
    @staticmethod
    def similarity(a: str, b: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ (0-1)"""
        return SequenceMatcher(None, a, b).ratio()
    
    @staticmethod
    def deduplicate_cases(cases: List[TestCaseItem], threshold: float = 0.85) -> List[TestCaseItem]:
        """å»é‡æµ‹è¯•ç”¨ä¾‹
        
        Args:
            cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯é‡å¤
            
        Returns:
            å»é‡åçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        """
        if not cases:
            return []
        
        unique_cases = []
        for case in cases:
            is_duplicate = False
            case_text = f"{case.ç”¨ä¾‹æ ‡é¢˜} {' '.join(case.æµ‹è¯•æ­¥éª¤)}"
            
            for unique_case in unique_cases:
                unique_text = f"{unique_case.ç”¨ä¾‹æ ‡é¢˜} {' '.join(unique_case.æµ‹è¯•æ­¥éª¤)}"
                if TestCaseDeduplicator.similarity(case_text, unique_text) > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_cases.append(case)
        
        return unique_cases
    
    @staticmethod
    def deduplicate_suite(suite: TestCaseSuite, threshold: float = 0.85) -> TestCaseSuite:
        """å»é‡æ•´ä¸ªæµ‹è¯•å¥—ä»¶"""
        deduplicated_modules = []
        
        for module in suite.æµ‹è¯•ç”¨ä¾‹:
            unique_cases = TestCaseDeduplicator.deduplicate_cases(
                module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨, 
                threshold
            )
            if unique_cases:
                deduplicated_modules.append(TestCaseModule(
                    åŠŸèƒ½æ¨¡å—=module.åŠŸèƒ½æ¨¡å—,
                    æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨=unique_cases
                ))
        
        return TestCaseSuite(æµ‹è¯•ç”¨ä¾‹=deduplicated_modules)


class XMindExporter:
    """XMind æ€ç»´å¯¼å›¾å¯¼å‡ºå™¨"""
    
    @staticmethod
    async def export(suite: TestCaseSuite, output_path: str, title: str = "æµ‹è¯•ç”¨ä¾‹") -> str:
        """å¯¼å‡ºä¸ºXMindæ–‡ä»¶
        
        Args:
            suite: æµ‹è¯•ç”¨ä¾‹å¥—ä»¶
            output_path: è¾“å‡ºç›®å½•
            title: æ€ç»´å¯¼å›¾æ ‡é¢˜
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        try:
            import xmind
            from xmind.core.markerref import MarkerId
        except ImportError:
            # å¦‚æœæ²¡æœ‰xmindåº“ï¼Œç”ŸæˆJSONæ ¼å¼çš„æ€ç»´å¯¼å›¾æ•°æ®
            return await XMindExporter._export_as_json(suite, output_path, title)
        
        # åˆ›å»ºXMindå·¥ä½œç°¿
        workbook = xmind.Workbook()
        sheet = workbook.getPrimarySheet()
        sheet.setTitle(title)
        
        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        root = sheet.getRootTopic()
        root.setTitle(title)
        
        # æ·»åŠ æ¨¡å—å’Œç”¨ä¾‹
        for module in suite.æµ‹è¯•ç”¨ä¾‹:
            module_topic = root.addSubTopic()
            module_topic.setTitle(f"ğŸ“ {module.åŠŸèƒ½æ¨¡å—}")
            
            for case in module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:
                case_topic = module_topic.addSubTopic()
                case_topic.setTitle(f"[{case.ä¼˜å…ˆçº§}] {case.ç”¨ä¾‹æ ‡é¢˜}")
                
                # æ·»åŠ æµ‹è¯•æ­¥éª¤
                if case.æµ‹è¯•æ­¥éª¤:
                    steps_topic = case_topic.addSubTopic()
                    steps_topic.setTitle("ğŸ“ æµ‹è¯•æ­¥éª¤")
                    for i, step in enumerate(case.æµ‹è¯•æ­¥éª¤, 1):
                        step_topic = steps_topic.addSubTopic()
                        step_topic.setTitle(f"{i}. {step}")
                
                # æ·»åŠ é¢„æœŸç»“æœ
                if case.é¢„æœŸç»“æœ:
                    results_topic = case_topic.addSubTopic()
                    results_topic.setTitle("âœ… é¢„æœŸç»“æœ")
                    for i, result in enumerate(case.é¢„æœŸç»“æœ, 1):
                        result_topic = results_topic.addSubTopic()
                        result_topic.setTitle(f"{i}. {result}")
        
        # ä¿å­˜æ–‡ä»¶
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"testcases_{timestamp}.xmind"
        filepath = output_dir / filename
        
        xmind.save(workbook, str(filepath))
        return str(filepath)
    
    @staticmethod
    async def _export_as_json(suite: TestCaseSuite, output_path: str, title: str) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼çš„æ€ç»´å¯¼å›¾æ•°æ® (å¤‡ç”¨æ–¹æ¡ˆ)"""
        mindmap_data = {
            "title": title,
            "topics": []
        }
        
        for module in suite.æµ‹è¯•ç”¨ä¾‹:
            module_data = {
                "title": f"ğŸ“ {module.åŠŸèƒ½æ¨¡å—}",
                "children": []
            }
            
            for case in module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:
                case_data = {
                    "title": f"[{case.ä¼˜å…ˆçº§}] {case.ç”¨ä¾‹æ ‡é¢˜}",
                    "children": [
                        {
                            "title": "ğŸ“ æµ‹è¯•æ­¥éª¤",
                            "children": [{"title": f"{i}. {s}"} for i, s in enumerate(case.æµ‹è¯•æ­¥éª¤, 1)]
                        },
                        {
                            "title": "âœ… é¢„æœŸç»“æœ",
                            "children": [{"title": f"{i}. {r}"} for i, r in enumerate(case.é¢„æœŸç»“æœ, 1)]
                        }
                    ]
                }
                module_data["children"].append(case_data)
            
            mindmap_data["topics"].append(module_data)
        
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"testcases_{timestamp}_mindmap.json"
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(mindmap_data, f, ensure_ascii=False, indent=2)
        
        return str(filepath)


class ExcelExporter:
    """Excel è¡¨æ ¼å¯¼å‡ºå™¨"""
    
    @staticmethod
    async def export(suite: TestCaseSuite, output_path: str, title: str = "æµ‹è¯•ç”¨ä¾‹") -> str:
        """å¯¼å‡ºä¸ºExcelæ–‡ä»¶
        
        Args:
            suite: æµ‹è¯•ç”¨ä¾‹å¥—ä»¶
            output_path: è¾“å‡ºç›®å½•
            title: å·¥ä½œè¡¨æ ‡é¢˜
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        try:
            import openpyxl
            from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
        except ImportError:
            # å¦‚æœæ²¡æœ‰openpyxlåº“ï¼Œç”ŸæˆCSVæ ¼å¼
            return await ExcelExporter._export_as_csv(suite, output_path, title)
        
        # åˆ›å»ºå·¥ä½œç°¿
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = title[:31]  # Excelå·¥ä½œè¡¨åæœ€é•¿31å­—ç¬¦
        
        # å®šä¹‰æ ·å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
        cell_alignment = Alignment(vertical="top", wrap_text=True)
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # å†™å…¥è¡¨å¤´
        headers = ["åŠŸèƒ½æ¨¡å—", "ç”¨ä¾‹ç¼–å·", "ç”¨ä¾‹æ ‡é¢˜", "ä¼˜å…ˆçº§", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ", "æµ‹è¯•æ•°æ®"]
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
            cell.border = thin_border
        
        # å†™å…¥æ•°æ®
        row = 2
        for module in suite.æµ‹è¯•ç”¨ä¾‹:
            for case in module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:
                ws.cell(row=row, column=1, value=module.åŠŸèƒ½æ¨¡å—).border = thin_border
                ws.cell(row=row, column=2, value=case.ç”¨ä¾‹ç¼–å·).border = thin_border
                ws.cell(row=row, column=3, value=case.ç”¨ä¾‹æ ‡é¢˜).border = thin_border
                ws.cell(row=row, column=4, value=case.ä¼˜å…ˆçº§).border = thin_border
                ws.cell(row=row, column=5, value=case.å‰ç½®æ¡ä»¶).border = thin_border
                ws.cell(row=row, column=6, value="\n".join(case.æµ‹è¯•æ­¥éª¤)).border = thin_border
                ws.cell(row=row, column=7, value="\n".join(case.é¢„æœŸç»“æœ)).border = thin_border
                ws.cell(row=row, column=8, value=json.dumps(case.æµ‹è¯•æ•°æ®, ensure_ascii=False)).border = thin_border
                
                # è®¾ç½®å¯¹é½æ–¹å¼
                for col in range(1, 9):
                    ws.cell(row=row, column=col).alignment = cell_alignment
                
                row += 1
        
        # è°ƒæ•´åˆ—å®½
        column_widths = [15, 12, 30, 8, 25, 40, 40, 30]
        for col, width in enumerate(column_widths, 1):
            ws.column_dimensions[openpyxl.utils.get_column_letter(col)].width = width
        
        # ä¿å­˜æ–‡ä»¶
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"testcases_{timestamp}.xlsx"
        filepath = output_dir / filename
        
        wb.save(str(filepath))
        return str(filepath)
    
    @staticmethod
    async def _export_as_csv(suite: TestCaseSuite, output_path: str, title: str) -> str:
        """å¯¼å‡ºä¸ºCSVæ ¼å¼ (å¤‡ç”¨æ–¹æ¡ˆ)"""
        import csv
        
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"testcases_{timestamp}.csv"
        filepath = output_dir / filename
        
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            
            # å†™å…¥è¡¨å¤´
            writer.writerow(["åŠŸèƒ½æ¨¡å—", "ç”¨ä¾‹ç¼–å·", "ç”¨ä¾‹æ ‡é¢˜", "ä¼˜å…ˆçº§", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ", "æµ‹è¯•æ•°æ®"])
            
            # å†™å…¥æ•°æ®
            for module in suite.æµ‹è¯•ç”¨ä¾‹:
                for case in module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:
                    writer.writerow([
                        module.åŠŸèƒ½æ¨¡å—,
                        case.ç”¨ä¾‹ç¼–å·,
                        case.ç”¨ä¾‹æ ‡é¢˜,
                        case.ä¼˜å…ˆçº§,
                        case.å‰ç½®æ¡ä»¶,
                        " | ".join(case.æµ‹è¯•æ­¥éª¤),
                        " | ".join(case.é¢„æœŸç»“æœ),
                        json.dumps(case.æµ‹è¯•æ•°æ®, ensure_ascii=False)
                    ])
        
        return str(filepath)


class StatisticsGenerator:
    """ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate(suite: TestCaseSuite) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            suite: æµ‹è¯•ç”¨ä¾‹å¥—ä»¶
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # åŸºç¡€ç»Ÿè®¡
        total_cases = suite.total_cases
        total_modules = suite.modules_count
        
        # ä¼˜å…ˆçº§åˆ†å¸ƒ
        priority_dist = {"P0": 0, "P1": 0, "P2": 0, "P3": 0}
        
        # æ¨¡å—ç»Ÿè®¡
        module_stats = []
        
        for module in suite.æµ‹è¯•ç”¨ä¾‹:
            module_case_count = len(module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨)
            module_priority_dist = {"P0": 0, "P1": 0, "P2": 0, "P3": 0}
            
            for case in module.æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:
                priority = case.ä¼˜å…ˆçº§
                priority_dist[priority] = priority_dist.get(priority, 0) + 1
                module_priority_dist[priority] = module_priority_dist.get(priority, 0) + 1
            
            module_stats.append({
                "æ¨¡å—åç§°": module.åŠŸèƒ½æ¨¡å—,
                "ç”¨ä¾‹æ•°é‡": module_case_count,
                "ä¼˜å…ˆçº§åˆ†å¸ƒ": module_priority_dist
            })
        
        return {
            "æ€»ç”¨ä¾‹æ•°": total_cases,
            "æ¨¡å—æ•°é‡": total_modules,
            "ä¼˜å…ˆçº§åˆ†å¸ƒ": priority_dist,
            "æ¨¡å—ç»Ÿè®¡": module_stats,
            "ç”Ÿæˆæ—¶é—´": datetime.now().isoformat()
        }


async def collect_and_organize_data(state: TestCaseState) -> Dict[str, Any]:
    """æ”¶é›†å’Œæ•´ç†æ•°æ® (æ­¥éª¤1)
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ•´ç†åçš„æ•°æ®
    """
    # è§£ææµ‹è¯•ç”¨ä¾‹
    parser = PydanticJSONParser()
    suite, errors = parser.parse_from_text(state.testcases)
    
    if errors:
        print(f"  âš ï¸ è§£æè­¦å‘Š: {errors}")
    
    if suite:
        print(f"  âœ… è§£ææˆåŠŸ: å…± {suite.total_cases} ä¸ªç”¨ä¾‹")
    else:
        print(f"  âŒ è§£æå¤±è´¥ï¼Œå°è¯•åˆ›å»ºç©ºç»“æ„")
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•åˆ›å»ºåŸºç¡€ç»“æ„
        suite = TestCaseSuite(æµ‹è¯•ç”¨ä¾‹=[
            TestCaseModule(
                åŠŸèƒ½æ¨¡å—="æœªåˆ†ç±»",
                æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨=[]
            )
        ])
    
    # å»é‡
    deduplicator = TestCaseDeduplicator()
    original_count = suite.total_cases
    suite = deduplicator.deduplicate_suite(suite)
    deduplicated_count = suite.total_cases
    
    return {
        "suite": suite,
        "original_count": original_count,
        "deduplicated_count": deduplicated_count,
        "removed_count": original_count - deduplicated_count,
        "parse_errors": errors
    }


async def export_to_xmind(suite: TestCaseSuite, output_path: str, title: str = "æµ‹è¯•ç”¨ä¾‹") -> Dict[str, Any]:
    """å¯¼å‡ºä¸ºXMind (æ­¥éª¤2)"""
    exporter = XMindExporter()
    filepath = await exporter.export(suite, output_path, title)
    return {
        "xmind_path": filepath,
        "success": True
    }


async def export_to_excel(suite: TestCaseSuite, output_path: str, title: str = "æµ‹è¯•ç”¨ä¾‹") -> Dict[str, Any]:
    """å¯¼å‡ºä¸ºExcel (æ­¥éª¤3)"""
    exporter = ExcelExporter()
    filepath = await exporter.export(suite, output_path, title)
    return {
        "excel_path": filepath,
        "success": True
    }


async def test_tool_node(state: TestCaseState) -> Dict[str, Any]:
    """æ•°æ®å¤„ç†ä¸“å®¶èŠ‚ç‚¹ - æŒ‰å›ºå®šé¡ºåºæ‰§è¡Œä»»åŠ¡
    
    è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰èŠ‚ç‚¹å‡½æ•°ï¼Œä¸æ˜¯åŸºäºLLMçš„Agentã€‚
    
    æ‰§è¡Œæµç¨‹:
    1. æ”¶é›†å’Œæ•´ç†æ•°æ®ï¼ˆå»é‡ã€éªŒè¯ï¼‰
    2. å¹¶è¡Œå¯¼å‡ºä¸ºXMindæ€ç»´å¯¼å›¾å’ŒExcelè¡¨æ ¼
    3. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    4. è¿”å›æ‰€æœ‰ä¸‹è½½é“¾æ¥
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€å­—å…¸
    """
    print("\n[5/5] æ•°æ®å¤„ç†ä¸“å®¶å¼€å§‹å·¥ä½œ...")
    
    # ç¡®å®šè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent.parent / "output"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ­¥éª¤1: æ”¶é›†å’Œæ•´ç†æ•°æ®
    print("  ğŸ“Š æ­¥éª¤1: æ”¶é›†å’Œæ•´ç†æ•°æ®...")
    collect_result = await collect_and_organize_data(state)
    suite = collect_result["suite"]
    
    if collect_result["removed_count"] > 0:
        print(f"  âœ… å»é‡å®Œæˆ: ç§»é™¤ {collect_result['removed_count']} ä¸ªé‡å¤ç”¨ä¾‹")
    
    # æ­¥éª¤2 & 3: å¹¶è¡Œå¯¼å‡ºXMindå’ŒExcel
    print("  ğŸ“ æ­¥éª¤2&3: å¹¶è¡Œå¯¼å‡ºæ–‡æ¡£...")
    
    xmind_task = export_to_xmind(suite, str(output_dir), "æµ‹è¯•ç”¨ä¾‹æ€ç»´å¯¼å›¾")
    excel_task = export_to_excel(suite, str(output_dir), "æµ‹è¯•ç”¨ä¾‹")
    
    xmind_result, excel_result = await asyncio.gather(
        xmind_task,
        excel_task,
        return_exceptions=True
    )
    
    # å¤„ç†ç»“æœ
    xmind_path = ""
    excel_path = ""
    
    if isinstance(xmind_result, dict) and xmind_result.get("success"):
        xmind_path = xmind_result["xmind_path"]
        print(f"  âœ… XMindå¯¼å‡ºå®Œæˆ: {xmind_path}")
    elif isinstance(xmind_result, Exception):
        print(f"  âš ï¸ XMindå¯¼å‡ºå¤±è´¥: {xmind_result}")
    
    if isinstance(excel_result, dict) and excel_result.get("success"):
        excel_path = excel_result["excel_path"]
        print(f"  âœ… Excelå¯¼å‡ºå®Œæˆ: {excel_path}")
    elif isinstance(excel_result, Exception):
        print(f"  âš ï¸ Excelå¯¼å‡ºå¤±è´¥: {excel_result}")
    
    # æ­¥éª¤4: ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("  ğŸ“ˆ æ­¥éª¤4: ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
    statistics = StatisticsGenerator.generate(suite)
    
    print(f"\n  ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"     - æ€»ç”¨ä¾‹æ•°: {statistics['æ€»ç”¨ä¾‹æ•°']}")
    print(f"     - æ¨¡å—æ•°é‡: {statistics['æ¨¡å—æ•°é‡']}")
    print(f"     - ä¼˜å…ˆçº§åˆ†å¸ƒ: {statistics['ä¼˜å…ˆçº§åˆ†å¸ƒ']}")
    
    # æ„å»ºè¿”å›ç»“æœ
    updates = {
        "xmind_path": xmind_path,
        "excel_path": excel_path,
        "statistics": statistics,
        "current_phase": "process",
        "process_completed": True,
    }
    
    print("\nâœ… æ•°æ®å¤„ç†ä¸“å®¶å®Œæˆ! æ‰€æœ‰å¤„ç†æ­¥éª¤å·²å®Œæˆ")
    
    return updates


async def run_tool_agent(state: TestCaseState) -> Dict[str, Any]:
    """è¿è¡Œæ•°æ®å¤„ç†ä¸“å®¶
    
    è¿™æ˜¯å¯¹å¤–æš´éœ²çš„æ¥å£ï¼Œä¸å…¶ä»–Agentä¿æŒä¸€è‡´çš„è°ƒç”¨æ–¹å¼ã€‚
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€å­—å…¸
    """
    return await test_tool_node(state)
