"""
RAGæ™ºèƒ½ä»£ç†ç¤ºä¾‹ï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•åˆ›å»ºä¸€ä¸ªåŸºäºRAGçš„æ™ºèƒ½ä»£ç†ï¼Œå®ƒå¯ä»¥ä»ç½‘é¡µå†…å®¹ä¸­æ£€ç´¢ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜
"""
import os
import sys
# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥è‡ªå®šä¹‰å·¥å…·
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import load_chat_model  # å¯¼å…¥è‡ªå®šä¹‰çš„èŠå¤©æ¨¡å‹åˆå§‹åŒ–å‡½æ•°ï¼ˆæ”¯æŒç¡…åŸºæµåŠ¨ï¼‰
from langchain_core.embeddings import DeterministicFakeEmbedding  # å¯¼å…¥åµŒå…¥æ¨¡å‹ï¼ˆç”¨äºå‘é‡åŒ–æ–‡æœ¬ï¼‰
from langchain_core.vectorstores import InMemoryVectorStore  # å¯¼å…¥å†…å­˜å‘é‡å­˜å‚¨
import bs4  # å¯¼å…¥BeautifulSoup4ï¼Œç”¨äºè§£æHTML
from langchain_community.document_loaders import WebBaseLoader  # å¯¼å…¥ç½‘é¡µåŠ è½½å™¨
from langchain.tools import tool  # å¯¼å…¥å·¥å…·è£…é¥°å™¨
from langchain_text_splitters import RecursiveCharacterTextSplitter  # å¯¼å…¥æ–‡æœ¬åˆ†å‰²å™¨
from langchain.agents import create_agent  # å¯¼å…¥åˆ›å»ºä»£ç†çš„å‡½æ•°

# å…¨å±€å˜é‡ç”¨äºæ‡’åŠ è½½
_model = None
_embeddings = None
_vector_store = None
_retrieve_tool = None

def _get_model():
    """å»¶è¿Ÿåˆå§‹åŒ–æ¨¡å‹"""
    global _model
    if _model is None:
        from utils import load_chat_model
        os.environ["SILICONFLOW_API_KEY"] = "sk-rmcrubplntqwdjumperktjbnepklekynmnmianaxtkneocem"
        _model = load_chat_model("siliconflow:deepseek-ai/DeepSeek-V3.2-Exp")
    return _model

def _get_embeddings():
    """å»¶è¿Ÿåˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
    global _embeddings
    if _embeddings is None:
        _embeddings = DeterministicFakeEmbedding(size=4096)
    return _embeddings

def _get_vector_store():
    """å»¶è¿Ÿåˆå§‹åŒ–å‘é‡å­˜å‚¨å’Œæ–‡æ¡£"""
    global _vector_store
    if _vector_store is None:
        print("ğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embeddings = _get_embeddings()
        _vector_store = InMemoryVectorStore(embeddings)
        
        # é…ç½®HTMLè§£æå™¨
        bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
        
        # åˆ›å»ºç½‘é¡µåŠ è½½å™¨
        loader = WebBaseLoader(
            web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
            bs_kwargs={"parse_only": bs4_strainer},
        )
        
        # åŠ è½½å’Œå¤„ç†æ–‡æ¡£
        docs = loader.load()
        assert len(docs) == 1, "åº”è¯¥åªåŠ è½½ä¸€ä¸ªæ–‡æ¡£"
        
        # æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            add_start_index=True,
        )
        
        all_splits = text_splitter.split_documents(docs)
        _vector_store.add_documents(documents=all_splits)
        print("âœ… æ–‡æ¡£åŠ è½½å®Œæˆ")
    
    return _vector_store

def _get_retrieve_tool():
    """å»¶è¿Ÿåˆå§‹åŒ–æ£€ç´¢å·¥å…·"""
    global _retrieve_tool
    if _retrieve_tool is None:
        @tool(response_format="content_and_artifact")
        def retrieve_context(query: str):
            """æ£€ç´¢ä¿¡æ¯ä»¥å¸®åŠ©å›ç­”æŸ¥è¯¢ã€‚
            
            è¿™ä¸ªå·¥å…·ä¼šåœ¨å‘é‡å­˜å‚¨ä¸­æœç´¢ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
            
            å‚æ•°:
                query: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜
                
            è¿”å›:
                åºåˆ—åŒ–çš„æ–‡æ¡£å†…å®¹å’ŒåŸå§‹æ–‡æ¡£å¯¹è±¡
            """
            vector_store = _get_vector_store()
            retrieved_docs = vector_store.similarity_search(query, k=2)
            
            serialized = "\n\n".join(
                (f"æ¥æº: {doc.metadata}\nå†…å®¹: {doc.page_content}")
                for doc in retrieved_docs
            )
            
            return serialized, retrieved_docs
        
        _retrieve_tool = retrieve_context
    return _retrieve_tool


# ============ åˆ›å»ºRAGä»£ç† ============

def get_rag_agent():
    """
    å·¥å‚å‡½æ•° - è¿”å› RAG Agentï¼ˆæ‡’åŠ è½½ç‰ˆæœ¬ï¼‰
    
    ä¾› LangGraph API ä½¿ç”¨
    
    Returns:
        RAG Agent å®ä¾‹
    """
    model = _get_model()
    tools = [_get_retrieve_tool()]
    
    prompt = (
        "ä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå·¥å…·ä»åšå®¢æ–‡ç« ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ã€‚"
        "ä½¿ç”¨è¿™ä¸ªå·¥å…·æ¥å¸®åŠ©å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
        "åœ¨å›ç­”ä¹‹å‰ï¼Œå…ˆæ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆã€‚"
    )
    
    agent = create_agent(model, tools, system_prompt=prompt)
    return agent


if __name__ == "__main__":
    query = (
        "ä»»åŠ¡åˆ†è§£çš„æ ‡å‡†æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ\n\n"
        "å¾—åˆ°ç­”æ¡ˆåï¼Œè¯·æŸ¥æ‰¾è¯¥æ–¹æ³•çš„å¸¸è§æ‰©å±•ã€‚"
    )
    
    agent = get_rag_agent()
    
    for event in agent.stream(
        {"messages": [{"role": "user", "content": query}]},
        stream_mode="values",
    ):
        event["messages"][-1].pretty_print()