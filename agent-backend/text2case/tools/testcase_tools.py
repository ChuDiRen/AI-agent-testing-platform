"""æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå·¥å…·æ¨¡å—

æä¾›æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆã€éªŒè¯ã€å¯¼å‡ºç­‰å·¥å…·å‡½æ•°
è¿™äº›å·¥å…·å¯ä»¥è¢« ReAct Agent è°ƒç”¨ï¼Œå®ç°å·¥å…·é©±åŠ¨çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
"""
import json
import re
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from difflib import SequenceMatcher
from enum import Enum

from langchain_core.tools import tool


# ============== æµ‹è¯•æ–¹æ³•é€‰æ‹©å·¥å…· ==============

class TestMethodType(Enum):
    """æµ‹è¯•æ–¹æ³•ç±»å‹"""
    EQUIVALENCE_CLASS = "equivalence_class"
    BOUNDARY_VALUE = "boundary_value"
    DECISION_TABLE = "decision_table"
    SCENARIO = "scenario"
    ORTHOGONAL = "orthogonal"
    CAUSE_EFFECT = "cause_effect"


METHOD_TEMPLATES = {
    TestMethodType.EQUIVALENCE_CLASS: """
## ç­‰ä»·ç±»åˆ’åˆ†æ³•
- è¯†åˆ«æ‰€æœ‰è¾“å…¥å‚æ•°
- ä¸ºæ¯ä¸ªå‚æ•°åˆ’åˆ†æœ‰æ•ˆç­‰ä»·ç±»å’Œæ— æ•ˆç­‰ä»·ç±»
- ä»æ¯ä¸ªç­‰ä»·ç±»é€‰å–ä»£è¡¨å€¼
- ä¼˜å…ˆçº§: æœ‰æ•ˆç­‰ä»·ç±»P0, æ— æ•ˆç­‰ä»·ç±»P1
""",
    TestMethodType.BOUNDARY_VALUE: """
## è¾¹ç•Œå€¼åˆ†ææ³•
- è¯†åˆ«æ‰€æœ‰æœ‰è¾¹ç•Œçš„è¾“å…¥å‚æ•°
- ç¡®å®šè¾¹ç•Œç‚¹: min, max
- è®¾è®¡è¾¹ç•Œå€¼: min-1, min, min+1, max-1, max, max+1
- è¾¹ç•Œç‚¹å¿…é¡»è¦†ç›–: P0
""",
    TestMethodType.DECISION_TABLE: """
## åˆ¤å®šè¡¨æ³•
- è¯†åˆ«æ‰€æœ‰æ¡ä»¶ï¼ˆè¾“å…¥ï¼‰å’ŒåŠ¨ä½œï¼ˆè¾“å‡ºï¼‰
- åˆ—å‡ºæ‰€æœ‰æ¡ä»¶ç»„åˆ
- ç¡®å®šæ¯ç§ç»„åˆå¯¹åº”çš„åŠ¨ä½œ
- æ¯æ¡è§„åˆ™å¯¹åº”ä¸€ä¸ªç”¨ä¾‹
""",
    TestMethodType.SCENARIO: """
## åœºæ™¯æ³•
- è¯†åˆ«åŸºæœ¬æµï¼ˆHappy Pathï¼‰
- è¯†åˆ«å¤‡é€‰æµï¼ˆæ­£å¸¸åˆ†æ”¯ï¼‰
- è¯†åˆ«å¼‚å¸¸æµï¼ˆé”™è¯¯å¤„ç†ï¼‰
- åŸºæœ¬æµå¿…é¡»å®Œæ•´è¦†ç›–: P0
""",
    TestMethodType.ORTHOGONAL: """
## æ­£äº¤æ³•
- è¯†åˆ«æ‰€æœ‰å› ç´ ï¼ˆå‚æ•°ï¼‰å’Œæ°´å¹³ï¼ˆå–å€¼ï¼‰
- é€‰æ‹©åˆé€‚çš„æ­£äº¤è¡¨
- æŒ‰æ­£äº¤è¡¨ç»„åˆè®¾è®¡ç”¨ä¾‹
- ç”¨Nä¸ªç”¨ä¾‹è¦†ç›–N^kç§ç»„åˆ
""",
    TestMethodType.CAUSE_EFFECT: """
## å› æœå›¾æ³•
- è¯†åˆ«åŸå› ï¼ˆè¾“å…¥æ¡ä»¶ï¼‰å’Œç»“æœï¼ˆè¾“å‡ºåŠ¨ä½œï¼‰
- åˆ†æå› æœå…³ç³»å’Œçº¦æŸ
- è½¬æ¢ä¸ºåˆ¤å®šè¡¨
- è¦†ç›–æ‰€æœ‰å› æœç»„åˆ
""",
}

FEATURE_KEYWORDS = {
    TestMethodType.EQUIVALENCE_CLASS: {
        "è¾“å…¥": 2, "éªŒè¯": 2, "æ ¡éªŒ": 2, "æ ¼å¼": 2, "ç±»å‹": 1,
        "æœ‰æ•ˆ": 2, "æ— æ•ˆ": 2, "ç”¨æˆ·å": 1, "å¯†ç ": 1, "é‚®ç®±": 1,
    },
    TestMethodType.BOUNDARY_VALUE: {
        "èŒƒå›´": 3, "é•¿åº¦": 3, "å¤§å°": 2, "æœ€å¤§": 3, "æœ€å°": 3,
        "è¾¹ç•Œ": 3, "é™åˆ¶": 2, "å­—ç¬¦": 2, "æ•°é‡": 2, "é‡‘é¢": 2,
    },
    TestMethodType.DECISION_TABLE: {
        "æ¡ä»¶": 3, "è§„åˆ™": 3, "é€»è¾‘": 2, "åˆ¤æ–­": 2, "å¦‚æœ": 2,
        "å¦åˆ™": 2, "å¹¶ä¸”": 2, "æˆ–è€…": 2, "æƒé™": 2, "çŠ¶æ€": 1,
    },
    TestMethodType.SCENARIO: {
        "æµç¨‹": 3, "æ­¥éª¤": 2, "åœºæ™¯": 3, "æ“ä½œ": 1, "ä¸šåŠ¡": 2,
        "è´­ä¹°": 2, "ä¸‹å•": 2, "æ³¨å†Œ": 2, "ç™»å½•": 2, "æ¥å£": 1,
    },
    TestMethodType.ORTHOGONAL: {
        "ç»„åˆ": 3, "é…ç½®": 3, "å‚æ•°": 1, "é€‰é¡¹": 2, "è®¾ç½®": 2,
        "å¤šä¸ª": 2, "æ­é…": 2, "å…¼å®¹": 2,
    },
    TestMethodType.CAUSE_EFFECT: {
        "ä¾èµ–": 3, "å…³è”": 3, "äº’æ–¥": 3, "çº¦æŸ": 3, "å‰æ": 2,
        "åˆ¶çº¦": 2, "å½±å“": 2, "è§¦å‘": 2,
    },
}


@tool
def select_test_methods(requirement: str, max_methods: int = 2) -> Dict[str, Any]:
    """æ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æµ‹è¯•æ–¹æ³•
    
    åˆ†æéœ€æ±‚ç‰¹å¾ï¼Œè¿”å›æ¨èçš„æµ‹è¯•æ–¹æ³•å’Œå¯¹åº”çš„æ¨¡æ¿æŒ‡å¯¼ã€‚
    è¿™æ˜¯ä¸€ä¸ªç¡®å®šæ€§å·¥å…·ï¼Œä¸æ¶ˆè€— LLM Tokenã€‚
    
    Args:
        requirement: éœ€æ±‚æè¿°æ–‡æœ¬
        max_methods: æœ€å¤šé€‰æ‹©å‡ ç§æ–¹æ³•ï¼Œé»˜è®¤2ç§
        
    Returns:
        åŒ…å«æ¨èæ–¹æ³•ã€æ¨¡æ¿å’ŒåŒ¹é…åˆ†æ•°çš„å­—å…¸
    """
    scores = {}
    req_lower = requirement.lower()
    
    for method_type, keywords in FEATURE_KEYWORDS.items():
        score = sum(weight for kw, weight in keywords.items() if kw in req_lower)
        scores[method_type] = score
    
    # æŒ‰åˆ†æ•°æ’åºé€‰æ‹©
    sorted_methods = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    selected = [m for m, s in sorted_methods if s >= 2][:max_methods]
    
    if not selected:
        selected = [TestMethodType.SCENARIO]
    
    # æ„å»ºæ¨¡æ¿
    templates = []
    method_names = {
        TestMethodType.EQUIVALENCE_CLASS: "ç­‰ä»·ç±»åˆ’åˆ†æ³•",
        TestMethodType.BOUNDARY_VALUE: "è¾¹ç•Œå€¼åˆ†ææ³•",
        TestMethodType.DECISION_TABLE: "åˆ¤å®šè¡¨æ³•",
        TestMethodType.SCENARIO: "åœºæ™¯æ³•",
        TestMethodType.ORTHOGONAL: "æ­£äº¤æ³•",
        TestMethodType.CAUSE_EFFECT: "å› æœå›¾æ³•",
    }
    
    for method in selected:
        templates.append(METHOD_TEMPLATES.get(method, ""))
    
    return {
        "recommended_methods": [method_names[m] for m in selected],
        "method_ids": [m.value for m in selected],
        "templates": "\n---\n".join(templates),
        "scores": {method_names[m]: scores[m] for m in selected},
    }


# ============== æµ‹è¯•æ•°æ®ç”Ÿæˆå·¥å…· ==============

@tool
def generate_test_data(
    field_name: str,
    field_type: str,
    constraints: Optional[str] = None
) -> Dict[str, Any]:
    """ç”Ÿæˆæµ‹è¯•æ•°æ®
    
    æ ¹æ®å­—æ®µç±»å‹å’Œçº¦æŸæ¡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆæœ‰æ•ˆå’Œæ— æ•ˆçš„æµ‹è¯•æ•°æ®ã€‚
    
    Args:
        field_name: å­—æ®µåç§°ï¼ˆå¦‚ username, email, ageï¼‰
        field_type: å­—æ®µç±»å‹ï¼ˆstring, integer, email, phone, dateï¼‰
        constraints: çº¦æŸæ¡ä»¶ï¼ˆå¦‚ "min:1, max:100, required"ï¼‰
        
    Returns:
        åŒ…å«æœ‰æ•ˆæ•°æ®ã€æ— æ•ˆæ•°æ®ã€è¾¹ç•Œæ•°æ®çš„å­—å…¸
    """
    result = {
        "field": field_name,
        "type": field_type,
        "valid_data": [],
        "invalid_data": [],
        "boundary_data": [],
    }
    
    # è§£æçº¦æŸ
    min_val, max_val, required = None, None, False
    if constraints:
        if "min:" in constraints:
            min_val = int(re.search(r'min:(\d+)', constraints).group(1))
        if "max:" in constraints:
            max_val = int(re.search(r'max:(\d+)', constraints).group(1))
        required = "required" in constraints
    
    if field_type == "string":
        result["valid_data"] = ["test_value", "ä¸­æ–‡æµ‹è¯•", "Test123"]
        result["invalid_data"] = ["", " ", None] if required else [None]
        if max_val:
            result["boundary_data"] = [
                "a" * (max_val - 1),
                "a" * max_val,
                "a" * (max_val + 1),
            ]
            result["invalid_data"].append("a" * (max_val + 100))
    
    elif field_type == "integer":
        min_val = min_val or 0
        max_val = max_val or 100
        result["valid_data"] = [min_val + 1, (min_val + max_val) // 2, max_val - 1]
        result["invalid_data"] = ["abc", None, 1.5, ""]
        result["boundary_data"] = [
            min_val - 1, min_val, min_val + 1,
            max_val - 1, max_val, max_val + 1,
        ]
    
    elif field_type == "email":
        result["valid_data"] = ["test@example.com", "user.name@domain.cn"]
        result["invalid_data"] = ["invalid", "@example.com", "test@", "test@.com", ""]
        result["boundary_data"] = ["a@b.cn", "a" * 50 + "@example.com"]
    
    elif field_type == "phone":
        result["valid_data"] = ["13800138000", "18612345678"]
        result["invalid_data"] = ["1380013800", "138001380001", "12345678901", "abcdefghijk"]
        result["boundary_data"] = ["10000000000", "19999999999"]
    
    elif field_type == "date":
        result["valid_data"] = ["2024-01-15", "2024-12-31"]
        result["invalid_data"] = ["2024-13-01", "2024-02-30", "invalid", ""]
        result["boundary_data"] = ["1970-01-01", "2099-12-31"]
    
    return result


# ============== æµ‹è¯•ç”¨ä¾‹éªŒè¯å·¥å…· ==============

@tool
def validate_testcase_format(testcase_text: str) -> Dict[str, Any]:
    """éªŒè¯æµ‹è¯•ç”¨ä¾‹æ ¼å¼æ˜¯å¦è§„èŒƒ
    
    æ£€æŸ¥æµ‹è¯•ç”¨ä¾‹æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µï¼Œæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚
    
    Args:
        testcase_text: æµ‹è¯•ç”¨ä¾‹æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
        
    Returns:
        éªŒè¯ç»“æœï¼ŒåŒ…å«æ˜¯å¦æœ‰æ•ˆã€é—®é¢˜åˆ—è¡¨ã€ç»Ÿè®¡ä¿¡æ¯
    """
    issues = []
    stats = {
        "total_cases": 0,
        "p0_count": 0,
        "p1_count": 0,
        "p2_count": 0,
        "p3_count": 0,
    }
    
    # æŸ¥æ‰¾æ‰€æœ‰ç”¨ä¾‹
    case_pattern = r'#{2,4}\s*(TC-?\d+)\s*([^\n]*)'
    cases = re.findall(case_pattern, testcase_text)
    stats["total_cases"] = len(cases)
    
    if not cases:
        issues.append("æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹ï¼ˆæ ¼å¼åº”ä¸º: ### TC-001 ç”¨ä¾‹æ ‡é¢˜ï¼‰")
        return {"valid": False, "issues": issues, "stats": stats}
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ["ä¼˜å…ˆçº§", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ"]
    for field in required_fields:
        if field not in testcase_text:
            issues.append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
    
    # ç»Ÿè®¡ä¼˜å…ˆçº§åˆ†å¸ƒ
    p0_matches = re.findall(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*P0', testcase_text)
    p1_matches = re.findall(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*P1', testcase_text)
    p2_matches = re.findall(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*P2', testcase_text)
    p3_matches = re.findall(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*P3', testcase_text)
    
    stats["p0_count"] = len(p0_matches)
    stats["p1_count"] = len(p1_matches)
    stats["p2_count"] = len(p2_matches)
    stats["p3_count"] = len(p3_matches)
    
    # æ£€æŸ¥ä¼˜å…ˆçº§åˆ†å¸ƒæ˜¯å¦åˆç†
    if stats["p0_count"] == 0:
        issues.append("è­¦å‘Š: æ²¡æœ‰P0çº§åˆ«çš„ç”¨ä¾‹ï¼Œæ ¸å¿ƒåŠŸèƒ½å¯èƒ½æœªè¦†ç›–")
    
    if stats["p0_count"] > stats["total_cases"] * 0.5:
        issues.append("è­¦å‘Š: P0ç”¨ä¾‹è¿‡å¤šï¼ˆ>50%ï¼‰ï¼Œä¼˜å…ˆçº§å¯èƒ½åˆ’åˆ†ä¸åˆç†")
    
    return {
        "valid": len([i for i in issues if not i.startswith("è­¦å‘Š")]) == 0,
        "issues": issues,
        "stats": stats,
    }


# ============== å¯¼å‡ºå·¥å…· ==============

@tool
def export_to_xmind(testcase_text: str, output_dir: Optional[str] = None) -> Dict[str, Any]:
    """å°†æµ‹è¯•ç”¨ä¾‹å¯¼å‡ºä¸ºXMindæ€ç»´å¯¼å›¾
    
    è§£ææµ‹è¯•ç”¨ä¾‹æ–‡æœ¬ï¼Œç”ŸæˆXMindæ ¼å¼çš„æ€ç»´å¯¼å›¾æ–‡ä»¶ã€‚
    
    Args:
        testcase_text: æµ‹è¯•ç”¨ä¾‹æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º text2case/output
        
    Returns:
        å¯¼å‡ºç»“æœï¼ŒåŒ…å«æ–‡ä»¶è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
    """
    from ..models import TestCaseSuite, TestCaseModule, TestCaseItem
    
    # è§£ææµ‹è¯•ç”¨ä¾‹
    cases_list = []
    case_pattern = r'#{2,4}\s*(TC-?\d+)\s*([^\n]*)'
    headers = list(re.finditer(case_pattern, testcase_text))
    
    for idx, match in enumerate(headers):
        case_id = match.group(1)
        case_title = match.group(2).strip() or case_id
        
        start = match.end()
        end = headers[idx + 1].start() if idx + 1 < len(headers) else len(testcase_text)
        content = testcase_text[start:end]
        
        # æå–å­—æ®µ
        priority_match = re.search(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*(\S+)', content)
        priority = priority_match.group(1) if priority_match else "P1"
        
        steps = re.findall(r'\d+\.\s*([^\n]+)', 
            re.search(r'\*\*æµ‹è¯•æ­¥éª¤\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL).group(1)
            if re.search(r'\*\*æµ‹è¯•æ­¥éª¤\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL) else "")
        
        expected = re.findall(r'\d+\.\s*([^\n]+)',
            re.search(r'\*\*é¢„æœŸç»“æœ\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL).group(1)
            if re.search(r'\*\*é¢„æœŸç»“æœ\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL) else "")
        
        cases_list.append(TestCaseItem(
            ç”¨ä¾‹ç¼–å·=case_id,
            ç”¨ä¾‹æ ‡é¢˜=case_title,
            ä¼˜å…ˆçº§=priority,
            æµ‹è¯•æ­¥éª¤=steps,
            é¢„æœŸç»“æœ=expected,
        ))
    
    if not cases_list:
        return {"success": False, "error": "æœªè§£æåˆ°æµ‹è¯•ç”¨ä¾‹"}
    
    # æ„å»ºæ€ç»´å¯¼å›¾æ•°æ®
    mindmap_data = {
        "title": "æµ‹è¯•ç”¨ä¾‹",
        "topics": [{
            "title": "ğŸ“ æµ‹è¯•ç”¨ä¾‹",
            "children": [{
                "title": f"[{c.ä¼˜å…ˆçº§}] {c.ç”¨ä¾‹æ ‡é¢˜}",
                "children": [
                    {"title": "ğŸ“ æµ‹è¯•æ­¥éª¤", "children": [{"title": f"{i}. {s}"} for i, s in enumerate(c.æµ‹è¯•æ­¥éª¤, 1)]},
                    {"title": "âœ… é¢„æœŸç»“æœ", "children": [{"title": f"{i}. {r}"} for i, r in enumerate(c.é¢„æœŸç»“æœ, 1)]},
                ]
            } for c in cases_list]
        }]
    }
    
    # ä¿å­˜æ–‡ä»¶
    output_path = Path(output_dir) if output_dir else Path(__file__).parent.parent / "output"
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filepath = output_path / f"testcases_{timestamp}_mindmap.json"
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(mindmap_data, f, ensure_ascii=False, indent=2)
    
    return {
        "success": True,
        "file_path": str(filepath),
        "total_cases": len(cases_list),
    }


@tool
def export_to_excel(testcase_text: str, output_dir: Optional[str] = None) -> Dict[str, Any]:
    """å°†æµ‹è¯•ç”¨ä¾‹å¯¼å‡ºä¸ºExcelè¡¨æ ¼
    
    è§£ææµ‹è¯•ç”¨ä¾‹æ–‡æœ¬ï¼Œç”ŸæˆExcelæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹è¡¨æ ¼ã€‚
    
    Args:
        testcase_text: æµ‹è¯•ç”¨ä¾‹æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º text2case/output
        
    Returns:
        å¯¼å‡ºç»“æœï¼ŒåŒ…å«æ–‡ä»¶è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
    """
    import csv
    
    # è§£ææµ‹è¯•ç”¨ä¾‹
    cases_data = []
    case_pattern = r'#{2,4}\s*(TC-?\d+)\s*([^\n]*)'
    headers = list(re.finditer(case_pattern, testcase_text))
    
    for idx, match in enumerate(headers):
        case_id = match.group(1)
        case_title = match.group(2).strip() or case_id
        
        start = match.end()
        end = headers[idx + 1].start() if idx + 1 < len(headers) else len(testcase_text)
        content = testcase_text[start:end]
        
        # æå–å­—æ®µ
        priority_match = re.search(r'\*\*ä¼˜å…ˆçº§\*\*[ï¼š:]\s*(\S+)', content)
        priority = priority_match.group(1) if priority_match else "P1"
        
        precondition_match = re.search(r'\*\*å‰ç½®æ¡ä»¶\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL)
        precondition = precondition_match.group(1).strip() if precondition_match else ""
        
        steps_match = re.search(r'\*\*æµ‹è¯•æ­¥éª¤\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL)
        steps = steps_match.group(1).strip() if steps_match else ""
        
        expected_match = re.search(r'\*\*é¢„æœŸç»“æœ\*\*[ï¼š:]([^*]+?)(?=\*\*|$)', content, re.DOTALL)
        expected = expected_match.group(1).strip() if expected_match else ""
        
        cases_data.append({
            "ç”¨ä¾‹ç¼–å·": case_id,
            "ç”¨ä¾‹æ ‡é¢˜": case_title,
            "ä¼˜å…ˆçº§": priority,
            "å‰ç½®æ¡ä»¶": precondition,
            "æµ‹è¯•æ­¥éª¤": steps,
            "é¢„æœŸç»“æœ": expected,
        })
    
    if not cases_data:
        return {"success": False, "error": "æœªè§£æåˆ°æµ‹è¯•ç”¨ä¾‹"}
    
    # ä¿å­˜æ–‡ä»¶
    output_path = Path(output_dir) if output_dir else Path(__file__).parent.parent / "output"
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å°è¯•ä½¿ç”¨ openpyxlï¼Œå¦åˆ™ä½¿ç”¨ CSV
    try:
        import openpyxl
        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
        
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "æµ‹è¯•ç”¨ä¾‹"
        
        # è¡¨å¤´æ ·å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        
        headers = ["ç”¨ä¾‹ç¼–å·", "ç”¨ä¾‹æ ‡é¢˜", "ä¼˜å…ˆçº§", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ"]
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
        
        for row, case in enumerate(cases_data, 2):
            ws.cell(row=row, column=1, value=case["ç”¨ä¾‹ç¼–å·"])
            ws.cell(row=row, column=2, value=case["ç”¨ä¾‹æ ‡é¢˜"])
            ws.cell(row=row, column=3, value=case["ä¼˜å…ˆçº§"])
            ws.cell(row=row, column=4, value=case["å‰ç½®æ¡ä»¶"])
            ws.cell(row=row, column=5, value=case["æµ‹è¯•æ­¥éª¤"])
            ws.cell(row=row, column=6, value=case["é¢„æœŸç»“æœ"])
        
        filepath = output_path / f"testcases_{timestamp}.xlsx"
        wb.save(str(filepath))
        
    except ImportError:
        # é™çº§ä¸º CSV
        filepath = output_path / f"testcases_{timestamp}.csv"
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ç”¨ä¾‹ç¼–å·", "ç”¨ä¾‹æ ‡é¢˜", "ä¼˜å…ˆçº§", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ"])
            writer.writeheader()
            writer.writerows(cases_data)
    
    return {
        "success": True,
        "file_path": str(filepath),
        "total_cases": len(cases_data),
    }


# ============== å·¥å…·é›†åˆ ==============

TESTCASE_TOOLS = [
    select_test_methods,
    generate_test_data,
    validate_testcase_format,
]

EXPORT_TOOLS = [
    export_to_xmind,
    export_to_excel,
]

__all__ = [
    "select_test_methods",
    "generate_test_data",
    "validate_testcase_format",
    "export_to_xmind",
    "export_to_excel",
    "TESTCASE_TOOLS",
    "EXPORT_TOOLS",
]
